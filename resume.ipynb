{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract as tes\n",
    "import re\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "tes.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread('resume_image1.jpg')\n",
    "img = cv2.imread('Resume.jpg')\n",
    "cv2.imshow(\"resume\",img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tes.image_to_data(img,output_type=tes.Output.DICT)\n",
    "# print(data['text'])\n",
    "dist_text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(data['text'])):\n",
    "#     if data['conf'][i]>50:\n",
    "#         for j in data['text'][i]:\n",
    "#                data['text'][i] = re.sub(r',.!','',data['text'][i].lower())\n",
    "#     print(data['text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', '', '', ' ', '', '', '', 'summary', '', '', 'data', 'science', 'developer', 'with', 'expertise', 'in', 'machine', 'learning', 'deep', 'learning', 'and', 'predictive', 'analytics', 'proficient', 'in', '', 'scikitlearn', 'and', 'tensorflow', 'with', 'experience', 'in', 'nlp', 'clustering', 'and', 'predictive', 'systems', 'skilled', 'in', 'modeling', 'feature', '', 'engineering', 'and', 'optimizing', 'performance', 'passionate', 'about', 'aldriven', 'innovation', 'and', 'deploying', 'scalable', 'data', 'solutions', '', 'completed', 'a', 'comprehensive', 'data', 'science', 'course', 'building', 'a', 'strong', 'foundation', 'in', 'both', 'theory', 'and', 'practice', 'holds', 'a', '', 'background', 'in', 'computer', 'science', 'engineering', '', '', '', ' ', '', '', '', ' ', '', '', '', ' ', '', '', '', ' ', '', '', '', 'technical', 'skills', '', '', 'languages', 'python', 'c', 'c', 'java', 'sql', '', '', 'frameworks', 'pandas', 'numpy', 'scikit', 'nltk', 'tensorflow', 'keras', '', '', '', ' ', '', '', '', ' ', '', '', '', '', 'tools', 'pycharm', 'git', 'mysql', 'google', 'colab', '', '', '', 'platforms', 'linux', 'windows', '', '', 'experience', '', '', '', 'euminar', 'technolab', 'hybrid', '', 'data', 'scientist', 'fulltime', 'september', '2024', '', 'present', '', '', '', '', 'developed', 'machine', 'learning', 'models', 'for', 'realworld', 'data', 'analysis', 'and', 'predictions', 'focusing', 'on', 'flight', 'delay', 'prediction', '', 'and', 'other', 'applied', 'projects', '', '', '', 'applied', 'data', 'preprocessing', 'techniques', 'including', 'handling', 'missing', 'values', 'label', 'encoding', 'and', 'feature', 'selection', '', 'based', 'on', 'correlation', 'to', 'prepare', 'datasets', 'for', 'analysis', '', '', '', 'applied', 'machine', 'learning', 'algorithms', 'for', 'classification', 'and', 'regression', 'tasks', 'optimizing', 'performance', 'through', '', 'feature', 'selection', 'and', 'hyperparameter', 'tuning', '', '', '', 'worked', 'with', 'large', 'datasets', 'and', 'leveraged', 'advanced', 'statistical', 'methods', 'to', 'derive', 'actionable', 'insights', '', '', '', '', 'worked', 'on', 'imbalanced', 'datasets', 'applying', 'oversampling', 'and', 'undersampling', 'methods', 'to', 'enhance', 'model', 'performance', '', 'and', 'robustness', '', '', '', ' ', '', '', '', '', 'collaborated', 'with', 'instructors', 'and', 'peers', 'to', 'iterate', 'on', 'model', 'performance', 'and', 'ensure', 'continuous', 'improvement', '', '', 'utilized', 'tools', 'like', 'scikitlearn', 'pandas', 'seaborn', 'and', 'tensorflow', 'to', 'process', 'data', 'visualize', 'results', 'and', 'deploy', '', 'models', 'in', 'handson', 'projects', '', '', '', ' ', '', '', '', 'projects', '', '', '', ' ', '', '', '', '', 'flight', 'delay', 'prediction', 'delaysense', '', '', 'developed', 'a', 'classification', 'model', 'to', 'predict', 'fight', 'del', '', '', '', ' ', '', '', '', 'ays', 'based', 'on', 'realtime', 'weather', 'data', 'using', 'scikitlearn', 'and', '', '', '', ' ', '', '', '', 'meteostat', '', '', 'applied', 'data', 'preprocessing', 'techniques', 'including', 'handling', 'missing', 'values', 'label', 'encoding', 'and', 'feature', 'selection', '', 'based', 'on', 'correlation', 'to', 'prepare', 'datasets', 'for', 'analysis', '', '', '', ' ', '', '', '', '', 'trained', 'models', 'optimizing', 'hyperparameters', 'using', 'grid', 'search', 'and', 'random', 'search', '', '', '', 'dealt', 'with', 'imbalanced', 'datasets', 'by', 'applying', 'smote', 'to', 'improve', 'model', 'training', 'and', 'performance', '', '', '', 'evaluated', 'model', 'performance', 'using', 'classification', 'metrics', 'like', 'accuracy', 'precision', 'recall', 'and', 'flscore', 'achieving', '', 'the', 'best', 'results', 'with', 'xgboost', '', '', '', '', 'smart', 'checkout', 'and', 'inventory', 'management', 'smartkhata', 'finalyear', 'project', '', '', '', 'developed', 'a', 'webbased', 'application', 'using', 'django', '', 'to', 'automate', 'checkout', 'and', 'inventory', 'management', 'for', 'small', '', 'retail', 'businesses', '', '', '', 'integrated', 'barcode', 'scanning', 'technology', 'to', 'facilitate', 'quick', 'billing', 'and', 'reduce', 'manual', 'entry', 'errors', '', '', '', 'designed', 'an', 'inventory', 'management', 'system', 'with', 'mysql', 'enabling', 'store', 'owners', 'to', 'monitor', 'stock', 'levels', 'and', '', 'generate', 'sales', 'reports', '', '', '', 'built', 'a', 'sales', 'data', 'visualization', 'feature', 'using', 'matplotlib', 'and', 'seaborn', 'enabling', 'shopkeepers', 'to', 'analyze', 'purchase', '', 'trends', '', '', '', 'tested', 'and', 'demonstrated', 'the', 'application', 'in', 'a', 'local', 'environment', 'ensuring', 'smooth', 'functionality', 'for', 'project', '', 'evaluation']\n"
     ]
    }
   ],
   "source": [
    "check_words = ['tensorflow','python','klearn','numpy','pandas','keras','seaborn']\n",
    "temp = []\n",
    "pattern = r',!'\n",
    "# pattern1 = r'\\b(' + '|'.join([re.escape(word) for word in check_words]) + r')\\b[^\\w]*'\n",
    "\n",
    "for i in range(len(data['text'])):\n",
    "    data['text'][i] = re.sub(pattern,'',data['text'][i].lower())\n",
    "    data['text'][i] = re.sub(r'[^\\w\\s]','',data['text'][i])\n",
    "\n",
    "print(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile Match : 85.71428571428571%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(data['text'])):\n",
    "    if data['conf'][i]>50:\n",
    "         if data['text'][i] in check_words:\n",
    "            # print(data['text'][i])\n",
    "            dist_text.append(data['text'][i])\n",
    "            cv2.rectangle(img,pt1=(data['left'][i],data['top'][i]),pt2=(data['left'][i]+data['width'][i],data['top'][i]+data['height'][i]),color=(125,0,0),thickness=3)        \n",
    "        # else:\n",
    "        #     continue\n",
    "cv2.imshow('test',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "dict1 = set(dist_text)\n",
    "print(f'Profile Match : {(len(dict1)/len(check_words))*100}%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(data['text'])):\n",
    "#     if data['conf'][i]>50:\n",
    "#         cv2.rectangle(img,pt1=(data['left'][i],data['top'][i]),pt2=(data['left'][i]+data['width'][i],data['top'][i]+data['height'][i]),color=(125,0,0),thickness=3)\n",
    "# cv2.imshow('test1',img)\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
